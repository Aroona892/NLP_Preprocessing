# âœ¨ NLP Preprocessing + Word2Vec Embedding

This notebook demonstrates essential **text preprocessing** techniques in Natural Language Processing (NLP), followed by training a **Word2Vec model** to learn word embeddings using `gensim`.

---

## ğŸ” Key Features

- âœ… Tokenization and lowercasing
- ğŸª’ Stemming with `PorterStemmer`
- â›” Stopword removal
- ğŸ§  Trains a `Word2Vec` model from tokenized sentences
- ğŸ”— Calculates word similarity scores using vector distances

---

## ğŸ§  Techniques Covered

- Text Cleaning  
- Word Tokenization  
- Stopword Filtering  
- Stemming  
- Word2Vec (Skip-gram / CBOW)

---

## ğŸ›  Libraries Used

- Python  
- NLTK  
- Gensim  
- Matplotlib (optional for visualization)

---

## ğŸš€ How to Run

1. Install dependencies:
```bash
pip install nltk gensim

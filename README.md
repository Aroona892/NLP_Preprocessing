# ✨ NLP Preprocessing + Word2Vec Embedding

This notebook demonstrates essential **text preprocessing** techniques in Natural Language Processing (NLP), followed by training a **Word2Vec model** to learn word embeddings using `gensim`.

---

## 🔍 Key Features

- ✅ Tokenization and lowercasing
- 🪒 Stemming with `PorterStemmer`
- ⛔ Stopword removal
- 🧠 Trains a `Word2Vec` model from tokenized sentences
- 🔗 Calculates word similarity scores using vector distances

---

## 🧠 Techniques Covered

- Text Cleaning  
- Word Tokenization  
- Stopword Filtering  
- Stemming  
- Word2Vec (Skip-gram / CBOW)

---

## 🛠 Libraries Used

- Python  
- NLTK  
- Gensim  
- Matplotlib (optional for visualization)

---

## 🚀 How to Run

1. Install dependencies:
```bash
pip install nltk gensim
